{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run this video-tagger on online video by providing a url\n",
    "# or offline video in local directory\n",
    "\n",
    "# you can skip the next 2 steps if you want to run the tagger on local video\n",
    "# instead provide the complete path here for your local video file\n",
    "filename = \"sample-videos/test-video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download video from youtube or a given public URL\n",
    "url = \"https://www.youtube.com/watch?v=JmNCPK15Bc0\"\n",
    "# save downloaded file as input.mp4\n",
    "filename = 'input.mp4'\n",
    "import youtube_dl\n",
    "ydl_opts = {'outtmpl': filename}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the video got downloaded correctly\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=640 height=480 src=input.mp4>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VGG-16 pre-trained model in Keras\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import few other libraries to pre-process image in Keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required to process the model output of keras\n",
    "from keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video and process it frame by frame\n",
    "import cv2\n",
    "stream = cv2.VideoCapture(filename)\n",
    "\n",
    "# for Mac OS, this is the code for writing mp4 files\n",
    "codec = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "frame_rate = 10\n",
    "# save tagged video output in output.mp4 file\n",
    "output = cv2.VideoWriter('output.mp4', codec, frame_rate, (1280,720), True)\n",
    "\n",
    "while 1:\n",
    "    flag, frame = stream.read()\n",
    "    if flag:\n",
    "        # resize frame for keras vgg-16 model\n",
    "        bgr_frame = cv2.resize(frame, (224, 224))\n",
    "        # covert OpenCV's BGR format to RGB for Keras\n",
    "        rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # following few routine steps to pre-process input image for Keras\n",
    "        input_image = image.img_to_array(rgb_frame)\n",
    "        input_image = np.expand_dims(input_image, axis=0)\n",
    "        input_image = preprocess_input(input_image)\n",
    "        \n",
    "        # finally, ready to run the model\n",
    "        predictions = model.predict(input_image)\n",
    "\n",
    "        text = \"\"\n",
    "        # decoding the model output\n",
    "        for label in decode_predictions(predictions, top=5)[0]:\n",
    "            # apply some threshold on confidence scores\n",
    "            if label[2] > 0.5:\n",
    "                text = label[1]\n",
    "                break\n",
    "\n",
    "        # print text on the image frame\n",
    "        cv2.putText(frame, text, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0,255,255))\n",
    "        output.write(frame)\n",
    "        cv2.imshow('Wild Life', frame)\n",
    "        \n",
    "        # standard stuff to wait after each frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "output.release()\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets check the output file created\n",
    "HTML('<iframe width=640 height=480 src=output.mp4>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yay, done..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
